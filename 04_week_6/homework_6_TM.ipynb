{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce9e7b35-0685-4578-8354-2d20a9ca8ef7",
   "metadata": {},
   "source": [
    "# Semana 6: Textmining\n",
    "\n",
    "Jose Manuel Coello\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Esta tarea consiste en trabajar preprocesamiento de texto utilizando\n",
    "técnicas de Text-Mining sobre textos en español de Cervantes, trabajaré\n",
    "principalmente con dos textos Capítulo I y Capítulo II del escrito “El\n",
    "ingenioso hidalgo don Quijote de la Mancha” que puede ser hallado en el\n",
    "siguiente\n",
    "[link](https://www.cervantesvirtual.com/obra-visor/el-ingenioso-hidalgo-don-quijote-de-la-mancha--0/html/fef04e52-82b1-11df-acc7-002185ce6064_2.html#I_5).\n",
    "Esta tarea tiene un alcance de lo que sería las etapas de recolección de\n",
    "datos mediante web scraping utilizando python y la estructuración de los\n",
    "datos, no entraré en detalle con la fase de modelado (modelo de\n",
    "clasificación o asociación).\n",
    "\n",
    "## Pasos a seguir para la obtención y estructuración de los datos\n",
    "\n",
    "Para la recolección de los datos se utilizarán principalmente los\n",
    "modulos `BeautifulSoup` y `re` para llevar a cabo el proceso de web\n",
    "scraping donde se extraerá el texto del Capítulo I y Capítulo II que se\n",
    "encuentran en el link anteriormente dicho y se guardarán ambos textos en\n",
    "dos variables `text1` y `text2` para luego elaborar el proceso de\n",
    "estructuración de datos.\n",
    "\n",
    "En la estructuración de los datos se crearán un conjunto de funciones\n",
    "donde cada una de ellas realizará una tarea en específico que se\n",
    "necesitan para el resultado final.\n",
    "\n",
    "Se procede a crear las siguientes funciones:\n",
    "\n",
    "1.  `my_token`: Función que elimina cualquier caracter especial en el\n",
    "    texto y cualquier conector o palabras que no aportan para el\n",
    "    resultado final. Esta función toma como argumentos (text, pattern,\n",
    "    remove) donde text es un string o cadena de texto, pattern una\n",
    "    expresión regular para eliminar caracteres no deseados y remove es\n",
    "    una lista que contiene palabras o cenectores que no se desean en el\n",
    "    texto. Esta función retorna un diccionario donde las claves son el\n",
    "    total de palabras contenidas en el texto y los valores serán el\n",
    "    conteo de la frecuencia de las palabras, a parte retorna un entero\n",
    "    que representa el total de palabras finales contenidas en el texto.\n",
    "\n",
    "2.  `all_words`: Función que fusiona dos diccionarios sumando los\n",
    "    valores con claves en común en ambos diccionarios y mantiene los\n",
    "    valores de las claves no comunes en los dos diccionarios. Esta\n",
    "    función toma como argumentos (dict1, dict2) donde ambos son\n",
    "    diccionarios que contienen las frecuencias de las palabras en los\n",
    "    textos que se desea analizar. Esta función retorna un diccionario\n",
    "    con el conteo de las frecuencias de las palabras en ambos textos.\n",
    "\n",
    "3.  `common_words`: Función para obtener frecuencias absolutas y\n",
    "    relativas para cada palabra contenida en una cadena de texto. Esta\n",
    "    función toma como argumento (dic, text, n, pattern), donde dic es un\n",
    "    diccionario con el conteo de frecuencias de palabras, text es la\n",
    "    cadena de texto que se desea analizar, n es un entero que representa\n",
    "    el top de las “n” palabras más frecuentes en el texto, pattern es\n",
    "    una expresión regular para eliminar caracteres no deseados. Esta\n",
    "    función retorna una lista anidada de longitud “n” donde cada\n",
    "    elemento de la lista es una lista que contiene: 1- la palabra, 2-\n",
    "    frecuencia absoluta y 3- frecuencia relativa en el texto.\n",
    "\n",
    "4.  `nice_print`: Función para imprimir los resultados de `common_words`\n",
    "    en un formato agradable y legible para el usuario final, esta\n",
    "    función toma como argumento el resultado arrojado por la función\n",
    "    `common_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9116223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to delete any special characters and count tokens\n",
    "def my_token(text, pattern = '[^A-Za-z0-9 ]+', remove = ['el','la','los']):\n",
    "  word_lst = re.sub(pattern, '', text).split(' ')\n",
    "  word_lst = [word for word in word_lst if word not in remove]\n",
    "  count_word = dict()\n",
    "  for w in word_lst:\n",
    "    count_word[w] = count_word.get(w, 0) + 1\n",
    "  return count_word, len(word_lst)\n",
    "\n",
    "# function to get absolute frequencies and relative frequencies for any word \n",
    "def common_words(dic, text, n = 10, pattern = '[^A-Za-z0-9]+'):\n",
    "  word_dict = list(dic.items())\n",
    "  word_dict.sort(reverse = True, key = lambda x: x[1])\n",
    "  div = len(re.sub(pattern, '', text))\n",
    "  word_dict = [list(tpl) + [round(tpl[1]/div, 4)] for tpl in word_dict[:n]]\n",
    "  return word_dict\n",
    "\n",
    "# function to print in a nice format common_words'result\n",
    "def nice_print(lst):\n",
    "  n_str = max([len(k[0]) for k in lst]) + 1\n",
    "  n1,n2 = 5,8\n",
    "  count = 1\n",
    "  for k in lst:\n",
    "    if count == 1:\n",
    "      print('N'.ljust(n1), 'Word'.ljust(n_str), 'Abs_freq'.ljust(n2), 'Relative_freq')\n",
    "    c = str(count).ljust(n1)\n",
    "    word = k[0].ljust(n_str)\n",
    "    abs_freq = str(k[1]).ljust(n2)\n",
    "    rel_freq = k[2]\n",
    "    print(c, word, abs_freq, rel_freq)\n",
    "    count += 1\n",
    "\n",
    "# function to merge two dictionaries and sum values from equal keys\n",
    "def all_words(dict1, dict2):\n",
    "  # keys contained only in dict1\n",
    "  only_dict1 = set(dict1.keys()).difference(set(dict2.keys()))\n",
    "  # keys contained only in dict2\n",
    "  only_dict2 = set(dict2.keys()).difference(set(dict1.keys()))\n",
    "  # keys contained in both dictionaries \n",
    "  dict1_dict2 = set(dict1.keys()).intersection(set(dict2.keys()))\n",
    "  # merge two dictionaries and sum the values \n",
    "  all_dict = {key: dict1[key] + dict2[key] for key in dict1_dict2}\n",
    "  all_dict.update({key: dict1[key] for key in only_dict1})\n",
    "  all_dict.update({key: dict2[key] for key in only_dict2})\n",
    "  return all_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04742bb8-6c88-44ad-b50c-52b11e2d1ea5",
   "metadata": {},
   "source": [
    "## Recolección y procesamiento de los datos\n",
    "\n",
    "Procedemos a crear el algoritmo para la extracción de los datos, se\n",
    "imprimen los primeros 300 caracteres de ambos textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66181721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capítulo I En un lugar de la\n",
      "Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que\n",
      "vivía un hidalgo de los de lanza en astillero, adarga\n",
      "antigua, rocín flaco y galgo corredor. Una olla de algo\n",
      "más vaca que carnero, salpicón las más noches,\n",
      "duelos y quebrantos los sábados, lantejas los v\n",
      "\n",
      "Capítulo II Hechas, pues,\n",
      "estas prevenciones, no quiso aguardar más tiempo a poner en\n",
      "efeto su pensamiento, apretándole a ello la falta que\n",
      "él pensaba que hacía en el mundo su tardanza,\n",
      "según eran los agravios que pensaba deshacer, tuertos que\n",
      "enderezar, sinrazones que enmendar, y abusos que mejorar\n"
     ]
    }
   ],
   "source": [
    "# modules\n",
    "import urllib.request, urllib.parse, urllib.error, re, csv, ssl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = 'https://www.cervantesvirtual.com/obra-visor/el-ingenioso-hidalgo-don-quijote-de-la-mancha--0/html/fef04e52-82b1-11df-acc7-002185ce6064_2.html#I_5_'\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "text1 = '' # text1 will be chapter one\n",
    "text2 = '' # text2 will be chapter two\n",
    "cap_tag = soup('h3')\n",
    "text_tag = soup('p')\n",
    "# start and end of chapter one and chapter two\n",
    "parrafos = ['^En un lugar de la.*', '^Limpias, pues, sus.*',\n",
    "            '^Hechas, pues,.*', '^Pusiéronle.*']\n",
    "\n",
    "# find the text of the chapter one and chapter two and save it in the variables text1 and text2\n",
    "find = False\n",
    "for t1 in cap_tag:\n",
    "  if 'Capítulo I' == t1.getText():\n",
    "    text1 += t1.getText() + ' '\n",
    "    for t2 in text_tag:\n",
    "      if re.search(parrafos[0], t2.getText()):\n",
    "        find = True\n",
    "\n",
    "      if find:\n",
    "        text1 += t2.getText() + ' '\n",
    "\n",
    "      if re.search(parrafos[1], t2.getText()):\n",
    "        find = False\n",
    "        break\n",
    "\n",
    "  if 'Capítulo II' == t1.getText():\n",
    "    text2 += t1.getText() + ' '\n",
    "    for t2 in text_tag:\n",
    "      if re.search(parrafos[2], t2.getText()):\n",
    "        find = True\n",
    "\n",
    "      if find:\n",
    "        text2 += t2.getText() + ' '\n",
    "\n",
    "      if re.search(parrafos[3], t2.getText()):\n",
    "        break\n",
    "    break\n",
    "\n",
    "print(text1[:300] + '\\n'+ '\\n' + text2[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbcd52-3d4b-450d-b42a-dc06c0c4f93e",
   "metadata": {},
   "source": [
    "Una vez teniendo ambos textos se procede a realizar la tokenización de\n",
    "los mismos, para ello utilizamos la función `my_token`, eliminamos\n",
    "caracteres especiales y palabras tales como conectores o pronombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0620691",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '[^A-Za-z0-9áéíóú ]'\n",
    "remove = ['el', 'él', 'los', 'la', 'del', 'de', 'y', 'que', 'a', 'en', 'su', 'se', 'muy',\n",
    "          'con', 'le', 'las', 'un', 'tan', 'por', 'no', 'si', 'al', 'ni', 'o', 'una',\n",
    "          'sus', 'me', 'para', 'lo', 'como', 'más', 'sin', 'tal', 'así', 'era', 'mi']\n",
    "text1_count, text1_len = my_token(text1, pattern = pattern, remove = remove)\n",
    "text2_count, text2_len = my_token(text2, pattern = pattern, remove = remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b21840-3b3d-446c-9586-21a350144840",
   "metadata": {},
   "source": [
    "Fusionamos ambos diccionarios, de esta manera obtenemos la frecuencia\n",
    "total de cada palabra en ambos textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcdec99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count = all_words(text1_count, text2_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf72fb-df9f-4734-b047-7ef0e4495b13",
   "metadata": {},
   "source": [
    "Una vez teniendo la frecuencia de cada palabra en ambos textos obtenemos\n",
    "la frecuencia relativa de cada palabra y almacenamos el resultado en una\n",
    "lista, donde cada elemento de la lista será una lista por cada palabra\n",
    "la cual contendrá su frecuencia absoluta y relativa. Se imprimen las 20\n",
    "palabras finales con mayor frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f92bc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N     Word       Abs_freq Relative_freq\n",
      "1     había      21       0.0012\n",
      "2     nombre     15       0.0009\n",
      "3     don        14       0.0008\n",
      "4     todo       13       0.0007\n",
      "5     porque     13       0.0007\n",
      "6     venta      12       0.0007\n",
      "7     caballero  11       0.0006\n",
      "8     Quijote    10       0.0006\n",
      "9     castillo   9        0.0005\n",
      "10    bien       9        0.0005\n",
      "11    esto       9        0.0005\n",
      "12    armas      9        0.0005\n",
      "13    cuando     9        0.0005\n",
      "14    celada     9        0.0005\n",
      "15    fue        8        0.0005\n",
      "16    vino       8        0.0005\n",
      "17    manera     7        0.0004\n",
      "18    todos      7        0.0004\n",
      "19    otros      6        0.0003\n",
      "20    puesto     6        0.0003\n"
     ]
    }
   ],
   "source": [
    "all_df = common_words(dic=all_count, text=text1+text2, n=1000)\n",
    "nice_print(all_df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83073c9-7df3-42c5-ab3e-7a824fbcfed4",
   "metadata": {},
   "source": [
    "Por último procedemos a obtener las frecuencias relativas de todas las\n",
    "palabras por separado, tanto en el texto 1 como en el texto 2 y\n",
    "calculamos el valor absoluto de la diferencia entre las frecuencias\n",
    "relativas, el resultado de la diferencia entre las frecuencias relativas\n",
    "se puede interpretar de la siguiente manera:\n",
    "\n",
    "Consideremos f1(w) y f2(w) la frecuencia relativa de la palabra “w” en\n",
    "el texto 1 y en el texto 2 respectivamente, si \\|f1(w) - f2(w)\\| ≈ f1(w)\n",
    "la probabilidad de que “w” este solo en el texto 1 es mayor a que este\n",
    "en el texto 2 y viceversa. Se imprimen las cien primeras palabras con\n",
    "mayor diferencia absoluta entre sus frecuencias relativas en el texto 1\n",
    "y texto 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66ab303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N               Word            Text1_Rel_Freq  Text2_Rel_Freq  Rel_Freq_Diff\n",
      "1               nombre          0.0129          0.0017          0.0112\n",
      "2               venta           0.0             0.0101          0.0101\n",
      "3               don             0.003           0.0093          0.0063\n",
      "4               había           0.0129          0.0067          0.0062\n",
      "5               castillo        0.001           0.0067          0.0057\n",
      "6               bien            0.0069          0.0017          0.0052\n",
      "7               dio             0.005           0.0             0.005\n",
      "8               Amadís          0.005           0.0             0.005\n",
      "9               sido            0.005           0.0             0.005\n",
      "10              Quijote         0.002           0.0067          0.0047\n",
      "11              estaba          0.005           0.0008          0.0042\n",
      "12              es              0.0             0.0042          0.0042\n",
      "13              fuera           0.0             0.0042          0.0042\n",
      "14              días            0.004           0.0             0.004\n",
      "15              leer            0.004           0.0             0.004\n",
      "16              muchas          0.004           0.0             0.004\n",
      "17              hecho           0.004           0.0             0.004\n",
      "18              armas           0.002           0.0059          0.0039\n",
      "19              todo            0.0079          0.0042          0.0037\n",
      "20              caballero       0.0069          0.0034          0.0035\n",
      "21              cuando          0.0059          0.0025          0.0034\n",
      "22              mozas           0.0             0.0034          0.0034\n",
      "23              puerta          0.0             0.0034          0.0034\n",
      "24              damas           0.0             0.0034          0.0034\n",
      "25              doncellas       0.0             0.0034          0.0034\n",
      "26              respondió       0.0             0.0034          0.0034\n",
      "27              todos           0.005           0.0017          0.0033\n",
      "28              cual            0.001           0.0042          0.0032\n",
      "29              luego           0.001           0.0042          0.0032\n",
      "30              alguna          0.001           0.0042          0.0032\n",
      "31              llamar          0.003           0.0             0.003\n",
      "32              gusto           0.003           0.0             0.003\n",
      "33              suyo            0.003           0.0             0.003\n",
      "34              llegaba         0.003           0.0             0.003\n",
      "35              hidalgo         0.003           0.0             0.003\n",
      "36              Gaula           0.003           0.0             0.003\n",
      "37              gigante         0.003           0.0             0.003\n",
      "38              cuerpo          0.003           0.0             0.003\n",
      "39              sí              0.003           0.0             0.003\n",
      "40              juicio          0.003           0.0             0.003\n",
      "41              verdad          0.003           0.0             0.003\n",
      "42              libros          0.003           0.0             0.003\n",
      "43              pues            0.003           0.0             0.003\n",
      "44              vino            0.005           0.0025          0.0025\n",
      "45              aquél           0.0             0.0025          0.0025\n",
      "46              día             0.0             0.0025          0.0025\n",
      "47              esta            0.0             0.0025          0.0025\n",
      "48              visera          0.0             0.0025          0.0025\n",
      "49              cuales          0.0             0.0025          0.0025\n",
      "50              pan             0.0             0.0025          0.0025\n",
      "51              seoras          0.0             0.0025          0.0025\n",
      "52              pensaba         0.0             0.0025          0.0025\n",
      "53              comer           0.0             0.0025          0.0025\n",
      "54              mío             0.0             0.0025          0.0025\n",
      "55              acaso           0.0             0.0025          0.0025\n",
      "56              risa            0.0             0.0025          0.0025\n",
      "57              ventero         0.0             0.0025          0.0025\n",
      "58              otro            0.0             0.0025          0.0025\n",
      "59              Mas             0.0             0.0025          0.0025\n",
      "60              algún           0.001           0.0034          0.0024\n",
      "61              vio             0.001           0.0034          0.0024\n",
      "62              mal             0.001           0.0034          0.0024\n",
      "63              cosa            0.001           0.0034          0.0024\n",
      "64              mucho           0.004           0.0017          0.0023\n",
      "65              mundo           0.004           0.0017          0.0023\n",
      "66              quien           0.003           0.0008          0.0022\n",
      "67              jamás           0.003           0.0008          0.0022\n",
      "68              mesmo           0.003           0.0008          0.0022\n",
      "69              antes           0.003           0.0008          0.0022\n",
      "70              pensamientos    0.003           0.0008          0.0022\n",
      "71              punto           0.003           0.0008          0.0022\n",
      "72              aun             0.003           0.0008          0.0022\n",
      "73              honraba         0.002           0.0             0.002\n",
      "74              fin             0.002           0.0             0.002\n",
      "75              Es              0.002           0.0             0.002\n",
      "76              ama             0.002           0.0             0.002\n",
      "77              leía            0.002           0.0             0.002\n",
      "78              nueva           0.002           0.0             0.002\n",
      "79              otra            0.002           0.0             0.002\n",
      "80              hermano         0.002           0.0             0.002\n",
      "81              caballeros      0.002           0.0             0.002\n",
      "82              caza            0.002           0.0             0.002\n",
      "83              hizo            0.002           0.0             0.002\n",
      "84              patria          0.002           0.0             0.002\n",
      "85              cobrase         0.002           0.0             0.002\n",
      "86              andantes        0.002           0.0             0.002\n",
      "87              gran            0.002           0.0             0.002\n",
      "88              partes          0.002           0.0             0.002\n",
      "89              primero         0.002           0.0             0.002\n",
      "90              industria       0.002           0.0             0.002\n",
      "91              desafíos        0.002           0.0             0.002\n",
      "92              Quijada         0.002           0.0             0.002\n",
      "93              mismo           0.002           0.0             0.002\n",
      "94              ejercicio       0.002           0.0             0.002\n",
      "95              casa            0.002           0.0             0.002\n",
      "96              heridas         0.002           0.0             0.002\n",
      "97              significativo   0.002           0.0             0.002\n",
      "98              lepareció       0.002           0.0             0.002\n",
      "99              decir           0.002           0.0             0.002\n",
      "100             buscar          0.002           0.0             0.002\n"
     ]
    }
   ],
   "source": [
    "x = [i[0] for i in all_df]\n",
    "\n",
    "data = []\n",
    "for word in x:\n",
    "  # get relative frequencies for all words in text1 and text2 \n",
    "  text1_rf = round(text1_count.get(word, 0) / text1_len, 4)\n",
    "  text2_rf = round(text2_count.get(word, 0) / text2_len, 4)\n",
    "  # compute the absolute value from the difference between the relative frequencies \n",
    "  diff = round(abs(text1_rf - text2_rf), 4)\n",
    "  # save in the data \n",
    "  data.append([word, text1_rf, text2_rf, diff])\n",
    "  \n",
    "data.sort(reverse = True, key = lambda x: x[3])\n",
    "data.insert(0, ['Word', 'Text1_Rel_Freq', 'Text2_Rel_Freq', 'Rel_Freq_Diff'])\n",
    "\n",
    "n = 15\n",
    "count = 0\n",
    "for lst in data[:101]:\n",
    "  if count == 0:\n",
    "    print('N'.ljust(n), lst[0].ljust(n), str(lst[1]).ljust(n), str(lst[2]).ljust(n), str(lst[3]))\n",
    "    count += 1\n",
    "    continue\n",
    "  print(str(count).ljust(n), lst[0].ljust(n), str(lst[1]).ljust(n), str(lst[2]).ljust(n), str(lst[3]))\n",
    "  count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
